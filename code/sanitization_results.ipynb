{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Sanitization Process for Data Privacy\n",
    "authors:\n",
    "- Juan Zinser \n",
    "tags:\n",
    "- knowledge-sharing\n",
    "- data\n",
    "- privacy\n",
    "created_at: 2018-01-30\n",
    "updated_at: 2018-01-30\n",
    "tldr: This is short description of the content and findings of the post.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanitization over Income Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The income data set can be downloaded here: [dataset](https://archive.ics.uci.edu/ml/datasets/census+income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juanzinser/Workspace/data_sanitization/venv/lib/python3.5/site-packages/ipykernel_launcher.py:64: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "/home/juanzinser/Workspace/data_sanitization/venv/lib/python3.5/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1ftt\n"
     ]
    }
   ],
   "source": [
    "from sanitization_tools import *\n",
    "import math\n",
    "import re\n",
    "income_dataset_path = \"census_level_0.csv\"\n",
    "model_dict = dict()\n",
    "model_dict[\"linear_regression\"] = linear_model.LinearRegression()\n",
    "model_dict[\"svm\"] = svm.SVC(gamma=0.001, C=100.)\n",
    "model_dict[\"naive_bayes\"] = naive_bayes.GaussianNB()\n",
    "model_dict[\"tree\"] = tree.DecisionTreeRegressor()\n",
    "cases = list()\n",
    "true_prob = None\n",
    "for pr in range(1,11): # si lo llevamos hasta 16 cubrimos de forma correcta otro par de columnas\n",
    "        cases += [[pr, False, True, True, true_prob, False],\n",
    "                  [pr, True, True, True, true_prob, False],\n",
    "                  [pr, False, True, True, true_prob, True],\n",
    "                  [pr, True, False, False, true_prob, False],\n",
    "                  [pr, False, False, False, true_prob, False],\n",
    "                  [pr, False, False, False, true_prob, True]]\n",
    "\n",
    "processed_cases = list()\n",
    "case_model_scores = dict()\n",
    "reco_list = list()\n",
    "for case in cases:\n",
    "    case_name = str(case[0])+(\"m\" if case[5] else \"t\" if case[1] else \"f\") +\\\n",
    "                (\"t\" if case[2] else \"f\")+(\"t\" if case[3] else \"f\")+(str(case[4]) if (case[1] and not case[2]) else \"\")\n",
    "    if case_name not in processed_cases:\n",
    "        data = pn.read_csv(income_dataset_path)\n",
    "\n",
    "        data_cols = data.columns\n",
    "        cat_columns = [u'workclass', u'education', u'marital-status', u'occupation',\n",
    "                   u'race', u'sex', u'native-country']\n",
    "\n",
    "        oh = preprocessing.OneHotEncoder()\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        all_columns = [\"age\"]\n",
    "        case2 = case\n",
    "        for col in cat_columns:\n",
    "            rel_privacy = math.ceil(float(case[0])/10*len(data[col].unique()))\n",
    "            case[0] = rel_privacy\n",
    "            cis = pn.DataFrame.from_dict(Counter(data[col]), \"index\").reset_index()\n",
    "            cis.columns = [\"class\", \"CIS\"]\n",
    "            field_dict = operator_model(data[col], *case2)\n",
    "            real_col = data[col]\n",
    "            data.drop(col, axis=1, inplace=True)\n",
    "            nis_rmse = dict()\n",
    "            for field in field_dict.keys():\n",
    "                field_name = \"_\".join([col, field])\n",
    "                data.loc[:, field_name] = field_dict[field]\n",
    "                rmse = ((real_col == field) - field_dict[field]).map(lambda x: x*x).sum()\n",
    "                nis_rmse[field] = rmse\n",
    "                if field_name not in all_columns:\n",
    "                    all_columns += [field_name]\n",
    "            nis = pn.DataFrame.from_dict(data.loc[:, [col+\"_\"+x for x in field_dict.keys()]].sum().to_dict(), \"index\").reset_index()\n",
    "            nis = pn.DataFrame.from_dict(nis_rmse, \"index\").reset_index()\n",
    "            nis.columns = [\"class\", \"NIS\"]\n",
    "\n",
    "            tmp_df = cis.merge(nis, how=\"left\")\n",
    "            tmp_df[\"column\"] = col\n",
    "            tmp_df[\"case\"] = case_name\n",
    "            reco_list.append(tmp_df)\n",
    "            \n",
    "        std_cols = [\"age\"]\n",
    "\n",
    "        std_scaler = preprocessing.StandardScaler()\n",
    "        for col in std_cols:\n",
    "            data.loc[:, col] = std_scaler.fit_transform(data[col].reshape(-1,1))\n",
    "\n",
    "        data_sanitized = data[all_columns + [\"salary-class\"]]\n",
    "        # data.to_csv(\"../data/hist_python/sanitized_census_\"+case_name+\".csv\")\n",
    "        # apply a suppervised algorithm\n",
    "        case_model_scores[case_name] = dict()\n",
    "        print(case_name)\n",
    "        for model_name, model in model_dict.items():\n",
    "            case_model_scores[case_name][model_name] = get_auc_score_of_model(data_sanitized, model)\n",
    "        processed_cases.append(case_name)\n",
    "\n",
    "reco_df = pn.concat(reco_list)\n",
    "reco_df.to_csv(\"supervised_df.csv\")\n",
    "\n",
    "df_models_scores = pn.DataFrame.from_dict(case_model_scores, orient=\"index\").reset_index().rename(columns={\"index\":\"case\"})\n",
    "df_models_scores = df_models_scores.melt(id_vars=[\"case\"]).rename(columns={\"variable\":\"model\"})\n",
    "\n",
    "df_models_scores[\"privacy\"] = df_models_scores[\"case\"].map(lambda x: re.findall(\"\\d+\", x)[0])\n",
    "df_models_scores[\"real\"] = df_models_scores[\"case\"].map(lambda x: re.findall(\"[^\\d]\",x)[0])\n",
    "df_models_scores[\"uniform\"] = df_models_scores[\"case\"].map(lambda x: int(re.findall(\"[^\\d]\",x)[1] == \"t\"))\n",
    "df_models_scores[\"uniform2\"] = df_models_scores[\"case\"].map(lambda x: int(re.findall(\"[^\\d]\",x)[2] == \"t\"))\n",
    "\n",
    "df_models_scores[\"error\"] = df_models_scores[\"value\"].map(lambda x: x[0])\n",
    "df_models_scores[\"auc\"] = df_models_scores[\"value\"].map(lambda x: x[1])\n",
    "    \n",
    "df_models_scores[\"roc_x\"] = df_models_scores[\"value\"].map(lambda x: all_entries_vector(x[2][0]))\n",
    "df_models_scores[\"roc_y\"] = df_models_scores[\"value\"].map(lambda x: all_entries_vector(x[2][1]))\n",
    "df_models = df_models_scores[[\"case\", \"model\", \"privacy\", \"real\", \"uniform\", \"uniform2\", \"error\", \"auc\", \"roc_x\", \"roc_y\"]]\n",
    "df_models.columns = [[\"case\", \"model\", \"privacy\", \"real\", \"uniform\", \"uniform2\", \"error\", \"auc\", \"roc_x\", \"roc_y\"]]\n",
    "df_models.to_csv(\"model_scores_roc.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanitization over Simulated Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from sanitization_tools import *\n",
    "import math\n",
    "import re\n",
    "column_size=1000\n",
    "nsim_case = 10\n",
    "cases = list()\n",
    "for nclasses in range(2, 30)[::1]:\n",
    "    for true_prob in [None]:\n",
    "        for pr in range(1, 11):\n",
    "            for class_dist in ['uniform','exponential']:\n",
    "                for nsim in range(nsim_case):\n",
    "                    cases += [[pr, nclasses, class_dist, False, True, True, true_prob, False],\n",
    "                              [pr, nclasses, class_dist, True, True, True, true_prob, False],\n",
    "                              [pr, nclasses, class_dist, False, True, True, true_prob, True],\n",
    "                              [pr, nclasses, class_dist, True, False, False, true_prob, False],\n",
    "                              [pr, nclasses, class_dist, False, False, False, true_prob, False],\n",
    "                              [pr, nclasses, class_dist, False, False, False, true_prob, True]]\n",
    "n=0\n",
    "processed_cases = list()\n",
    "reco_df = pn.DataFrame(columns=[\"case\", \"class\", \"CIS\", \"NIS\"])\n",
    "rmse_by_case = dict()\n",
    "def process_case(case_t):\n",
    "    case = case_t[0]\n",
    "    cases = case_t[1]\n",
    "    case_name = str(case[0])+(\"m\" if case[7] else (\"t\" if case[3] else \"f\")) + (\"t\" if case[4] else \"f\") + \\\n",
    "                (\"t\" if case[5] else \"f\") #+ (str(case[6]) if (case[3] and not case[4]) else \"\")\n",
    "    case_name += '_' + str(case[1]) + '_' + str(case[2])\n",
    "    nclasses = case[1]\n",
    "    class_dist = case[2]\n",
    "    print(class_dist)\n",
    "    p = [1./nclasses]*nclasses if class_dist == 'uniform' else expo_weights(nclasses)\n",
    "    sim_data = np.random.choice(range(nclasses), column_size, p=p)\n",
    "    #if case_name not in processed_cases:\n",
    "    cis = pn.DataFrame.from_dict(Counter(sim_data), \"index\").reset_index()\n",
    "    cis.columns = [\"class\", \"CIS\"]\n",
    "    case2 = case\n",
    "    case2.pop(1)\n",
    "    case2.pop(1)\n",
    "    rel_privacy = math.ceil(float(case[0])/10*nclasses)\n",
    "    case2[0] = rel_privacy\n",
    "    field_dict = operator_model(sim_data, *case2)\n",
    "    #print(field_dict)\n",
    "    nis = pn.DataFrame.from_dict(field_dict).sum(axis=0).reset_index()\n",
    "    nis.columns = [\"class\", \"NIS\"]\n",
    "    tmp_df = cis.merge(nis, how=\"left\")\n",
    "    tmp_df['RMSE'] = (tmp_df['CIS'] - tmp_df['NIS']).map(lambda x: x*x)\n",
    "    tmp_df['CHI'] = (tmp_df['RMSE']/tmp_df['CIS'].map(lambda x: x if x>0.0 else np.nan))\n",
    "    rmse_one = math.sqrt(sum(tmp_df['RMSE'].values))\n",
    "    chi_one = np.nansum(tmp_df['CHI'].values)\n",
    "    return (case_name, rmse_one, chi_one)\n",
    "\n",
    "\n",
    "pool = multiprocessing.Pool()\n",
    "cases_results = pool.map(process_case, [(case,cases) for case in cases])\n",
    "\n",
    "rmse_df = pn.DataFrame(cases_results)\n",
    "rmse_df.columns = [\"case\", \"rmse\", \"chi\"]\n",
    "rmse_df[\"privacy\"] = rmse_df[\"case\"].map(lambda x: re.findall(\"\\d+\", x)[0])\n",
    "rmse_df[\"real\"] = rmse_df[\"case\"].map(lambda x: re.findall(\"[^\\d]\",x)[0])\n",
    "rmse_df[\"uniform\"] = rmse_df[\"case\"].map(lambda x: int(re.findall(\"[^\\d]\",x)[1] == \"t\"))\n",
    "rmse_df[\"uniform2\"] = rmse_df[\"case\"].map(lambda x: int(re.findall(\"[^\\d]\",x)[2] == \"t\"))\n",
    "rmse_df[\"nclasses\"] = rmse_df[\"case\"].map(lambda x: re.findall(\"\\d+\", x)[1])\n",
    "rmse_df[\"uniform_original\"] = rmse_df[\"case\"].map(lambda x: int(x.split(\"_\")[-1] == \"uniform\"))\n",
    "rmse_df.to_csv(\"df_simulated_rel.csv\")"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
